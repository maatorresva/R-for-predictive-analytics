{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aprendizaje de maquinas  -- R -- Modelos Gráficos Probabilisticos.\n",
    "Notas de clase sobre aprendizaje de maquinas usando R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Juan David Velásquez Henao**   \n",
    "jdvelasq@unal.edu.co  \n",
    "Universidad Nacional de Colombia, Sede Medellín  \n",
    "Facultad de Minas  \n",
    "Medellín, Colombia  \n",
    "\n",
    "[Licencia]\n",
    "\n",
    "[Readme]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Software utilizado**.\n",
    "\n",
    "> Este es un documento interactivo escrito como un notebook de [Jupyter](http://jupyter.org), en el cual se presenta un tutorial sobre regresión logistica usando **R** en el contexto de aprendizaje de maquinas. Los notebooks de Jupyter permiten incoporar simultáneamente código, texto, gráficos y ecuaciones. El código presentado en este notebook puede ejecutarse en los sistemas operativos Linux y OS X.\n",
    "\n",
    "> Haga click [aquí](https://github.com/jdvelasq/guias-de-instalacion) para obtener instrucciones detalladas sobre como instalar Jupyter en Windows y Mac OS X.\n",
    "\n",
    "> Haga clic [aquí] para ver la última versión de este documento en nbviewer.\n",
    "\n",
    "> Descargue la última versión de este documento a su disco duro; luego, carguelo y ejecutelo en línea en [Try Jupyter!](https://try.jupyter.org)\n",
    "\n",
    "> Haga clic [aquí](https://github.com/jdvelasq/ETVL-R/blob/master/ETVL-R-5-visualizacion-1-base.ipynb) para ver el tutorial de visualización y gráficas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Contenido"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> * [Introducción](#Introducción)\n",
    "* [Teoría de Grafos](#Teoría-de-Grafos)\n",
    "* [Teorema de Bayes](#Teorema-de-Bayes)\n",
    "    * [Independencia Condicional](#Independencia-Condicional)\n",
    "    * [Redes Bayesianas](#Redes-Bayesianas)\n",
    "    * [Clasificador Bayesiano Ingenuo](#Clasificador-Bayesiano-Ingenuo)\n",
    "    * [Aplicación](#Aplicación)\n",
    "* [ Modelos de Markov Ocultos](#Modelos-de-Markov-Ocultos)\n",
    "    * [Aplicación HMM](#Aplicación-HMM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bibliografía**.\n",
    "\n",
    ">  \n",
    "\n",
    "**Material complementario.**\n",
    "> Webinar RStudio [Getting your data into R](https://www.rstudio.com/resources/webinars/getting-your-data-into-r/) \n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducción\n",
    "\n",
    "[Contenido](#Contenido)\n",
    "\n",
    "Los modelos gráficos probabilisticos son representaciones en forma de grafo que describen la relación de independencia condicional entre un conjunto de variables aleatorias. Estos modelos proporcionan un marco poderoso para modelar las interacciones complejas entre varias variables aleatorias Y han sido existosamente aplicados a diagnostico médico así como a segmentación de imágenes.\n",
    "\n",
    "Estos modelos manejan dos conceptos principales de dos ramas de la matemática, :\n",
    "\n",
    "* Teoría de grafos. \n",
    "* Teoría de probabilidad.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Teoría de Grafos\n",
    "[Contenido](#Contenido)\n",
    "\n",
    "\n",
    "Esta sub-rama de la matemática estudia los objetos conocidos como grafos, los cuales consisten de dos conjuntos: _**vértices (o nodos) enumerados y las conexiones entre los vértices (o bordes)**_. Por lo tanto, un grafo no es nada más que una descripción de puntos y conexiones entre ellos. Cada uno de estas conexiones pueden tener direcciones (flechas) que van _**desde el nodo fuente o cola hasta el vértice objetivo o cabeza**_. Cuando el grafo presenta direcciones se le denomina un _**grafo dirigido**_, de lo contrario se denomina un _**grafo no dirigido**_ donde las conexiones se representan con lineas y no flechas.\n",
    "\n",
    "<img src=\"images/graph.png\" height=500 width=400>\n",
    "\n",
    "Una forma común de describir un grafo como el anterior es a través de una _**matriz de adyacencia**_. Si tenemos $ V $ vértices en el grafo, una matriz de adyacencia es de dimensión $ V \\times V $ cuyas entradas son cero si el vertice del número de la fila no está conectado con el vértice del número de la columna. Si existe una conexión, el valor es 1. Cuando se trata de grafos no dirigidos, la matriz siempre es simetrica. \n",
    "\n",
    "Un vértice se denomina $ v_{i} $ mientras que un borde o conexión se denomina $ (v_{i},v_{j}) $ donde el vértice $ i $ es la fuente y el vértice $ j $ es el destino. Por lo tanto se dice que dos vertices están conectados si tienen un _**camino**_ representado por una o varias conexiones entre los nodos que permitan llegar de $ i $ hasta $ j $. Por ejemplo, los nodos 2 y 6 están conectados ya que pasando a través del nodo 1 se pueden llegar. No obstante, note que del 6 al 2 no existe camino.\n",
    "\n",
    "Cabe aclarar que no importa la posición de los puntos o conexiones, solo es relevante que las conexiones entre los nodos se encuentren correctas. Es por esto que para los dos grafos mostrados se pueden representar con la misma matriz de adyacencia.\n",
    "\n",
    "<img src=\"images/matrix.png\" height=200 width=200>\n",
    "\n",
    "Dado que para dos vertices cualesquiera pueden existir varios caminos, definimos la _**distancia**_ entre dos nodos como el camino más corto entre ellos, esto es la longitud medida en nodos de dicho camino. Por lo tanto, la distancia entre el nodo 2 y 6, es igual a 1.\n",
    "\n",
    "Adicionalmente un camino que empieza y termina en el mismo vértice se le conoce como un _**ciclo**_. Cuando un grafo no tiene un ciclo se le conoce como un _**grafo aciclico**_. Adicional, cuando tiene direcciones se le conoce como un _**grafo acíclico dirigido (DAG por sus siglas en inglés)**_.\n",
    "\n",
    "Muchos fenómenos reales pueden ser representandos como un grafo, ya sea las conexiones de amigos en facebook, o las redes de internet, de telecomunicaciones, de transporte, de electriciadad, etc. \n",
    "\n",
    "Dentro de la aplicación de aprendizaje de maquinas, asumimos que los nodos son variables aleatorias y las conexiones son las dependencias entre ellas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Teorema de Bayes\n",
    "[Contenido](#Contenido)\n",
    "\n",
    "\n",
    "Para explorar más las variables aleatorias, se hace una corta introdución al teorema de Bayes. Para esto suponga que hay  dos eventos $ A $ y $ B $. Por ejemplo el evento $ A $ puede ser que un paciente tenga apendicitis y el evento $ B $ que dicho paciente tenga alto nivel de globulos blancos. Por lo tanto, se define la probabilidad condicional de $ A $ dado $ B $ como lq proabilidad de que el evento $ A $ d suceda dado que el evento $ B $ ha sucedido anteriormente.\n",
    "\n",
    "Matemáticamente, se define la proabilidad condicional como la división entre la probabilidad de que los dos eventos ocurran divido por la probabilidad de que el evento B ocurra:\n",
    "\n",
    "$$ P(A|B)= \\frac{P(A \\cap B)}{P(B)} $$\n",
    "\n",
    "Note que si los eventos son independientes entre sí la ecuación es simplemente la probabilidad de $ A $, lo cual es consistente ya que la ocurrencia de $ B $ no influye en la probabilidad de $ B $.\n",
    "\n",
    "$$ P(A|B)= \\frac{P(A)·P(B)}{P(B)} = P(A) $$\n",
    "\n",
    "Por lo tanto se puede reexpresar la probabilidad conjunta como:\n",
    "\n",
    "$$ P(A \\cap B) = P(A|B) · P(B) = P(B|A)·P(A) $$\n",
    "\n",
    "Luego, se define el teorema de Bayes como:\n",
    "\n",
    "$$ P(A|B)= \\frac{P(B|A)·P(A)}{P(B)} = \\frac{P(B|A)}{P(B)}·P(A)$$\n",
    "\n",
    "La anterior ecuación representa la probabilidad posterior de $ A $ dado que ha ocurrido $ B $, donde $ P(A) $ es la probabilidad a priori de la ocurrencia de $ B $ y el coeficiente  $  \\frac{P(B|A)}{P(B)} $ es el ajuste de la nueva información del evento $ B $ una vez ha ocurrido."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Independencia Condicional\n",
    "[Contenido](#Contenido)\n",
    "\n",
    "Existen ocasiones cuando dos variables $A, B$ puede que no sean estadísticamente independientes en el principio, pero observando una tercera variable $C$, puede resultar en que se vuelvan independientes. Formalmente, se define como:\n",
    "\n",
    "$$ P(A \\cap B | C)=P(A|C) · P(B|C) $$\n",
    "\n",
    "Por ejemplo, si $J$ representa la probabilidad de que se le ofrezca una oferta de trabajo en una compañía y $G$ la probabilidad de ser aceptado en un estudio de posgrado en cierta universidad, puede ser que estos dos eventos son independientes dado que existen varios factores que influyen en estos eventos (entrevistas, candidatos, etc). No obstante, ambos pueden depender en la variable $U$ representando el desempeño de la persona en sus estudios universitarios. \n",
    "\n",
    "Por lo tanto, si se desconoce $U$ pero se sabe que la persona fue aceptada en el estudio de posgrado puede incrementar la creencia en la probabilidad de conseguir un trabajo, ya que que en cierto modo tuvo un buen desempeño en sus estudios de la universidad. Luego, los eventos $J$ y $G$ no son tan independientes del todo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Redes Bayesianas\n",
    "[Contenido](#Contenido)\n",
    "\n",
    "Las redes bayesianas son un tipo de grafos dirigidos acíclicos donde usualmente se les denomina a los nodos fuente y destino como nodos padres e hijos (o descendientes), respectivamente. En caso que exista un camino entre $A$ y $B$, se dice que $B$ es descendiente directo de $A$ y, dado que el grafo no tiene ciclos, la relación es mutualmente exclusiva.\n",
    "\n",
    "Por lo tanto, las redes bayesianas tienen una propiedad donde dado los nodos padres, cada nodo en la red es condicionalmente independiente de todos los otros nodos que no sean descendientes. A lo anterior, se le denomina la propiedad de Markov local, lo cual permite factorizar la probabilidad conjunta de todas las variables aleatorias tomando en cuenta todos los nodos del grafo.\n",
    "\n",
    "Ilustrando, para las tres variables $G, J, U$ se puede expresar:\n",
    "\n",
    "$$ P(G,J,U)=P(G|J,U)·P(J,U)=P(G|J,U)·P(J|U)·P(U) $$\n",
    "\n",
    "Esta regla es general y se puede aplicar a más variables sin perdida de generalidad, lo que permite simplificar cálculos ya que no se considera todas las combinaciones posibles, sino unicamente las que especifica la fórmula."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Clasificador Bayesiano Ingenuo\n",
    "[Contenido](#Contenido)\n",
    "\n",
    "El primer modelo gráfico probabilistico es el Clasificador Bayesiando Ingenuo, el cual es un modelo DAG que contiene un nodo padre y una serie de nodos hijos representando variables aleatorias que son dependientes solo del nodo padre sin depedencia entre ellas.\n",
    "\n",
    "<img src=\"images/naive.png\" height=500 width=300>\n",
    "\n",
    "Usualmente el nodo padre se le conoce como el nodo causal donde, por ejemplo, el nodo \"Sentimiento\" influye en el nodo \"triste\", \"divertido\", etc. Por lo tanto, para realizar estimaciones en el nodo padre a partir de observaciones de los nodos hijos (es decir, los nodos hijos son las variables predictoras y el nodo padre la variable respuesta) se puede reexpresar la probabilidad conjunta como:\n",
    "\n",
    "$$ P(C|F_{1},...,F_{n}) = \\frac{P(C)·P(F_{1},...,F_{n}|C)}{P(F_{1},...,F_{n})} $$\n",
    "\n",
    "Por lo tanto,se asume independencia de la red:\n",
    "\n",
    "$$ P(C|F_{1},...,F_{n}) = \\frac{P(C)· P(F_{1}|C)·...·P(F_{n}|C)}{P(F_{1},...,F_{n})} $$\n",
    "\n",
    "Luego, para realizar un clasificador usando esta fórmula, el objetivo es escoger la clase $C_{i}$ que maximice la probabilidad posterior de una clase dadas unas características $P(C_{i}|F_{1},...,F_{n})$. Dado que el denominador no es influenciado por la clase $C_{i}$, el problema se convierte en maximizar el numerador:\n",
    "\n",
    "$$ Clasificar \\hspace{0.25cm} C_{i}: \\underset{c}{\\arg\\max} P(C) · \\prod_{i=1}^{n}P(F_{i}|C) $$\n",
    "\n",
    "A partir de los datos se puede estimar las probabilidades $ P(F_{i}|C_{j}) $ como las proporciones relativas de las observaciones de la clase $C_{j}$ que tienen diferente valor de la variable $F_{i}$. También se puede estimar $P(C_{j}$ como la proporcion relativa de las observaciones que están asiganas a la clase $C_{j}$. Estos son los estimadores de máxima verosimilitud."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aplicación\n",
    "[Contenido](#Contenido)\n",
    "\n",
    "El análisis de sentimientos, la tarea es analizar un determinado fragmento de texto para determinar el sentimiento que está siendo expresado por el autor, ya sea en blogs, twitters, noticias, etc. determinando si la reaccion es positiva, neutral o negativa.\n",
    "\n",
    "Abarcar este problema se puede realizar a través de los modelos gráficos probabilisticos, donde el sentimiento (positivo o negativo) es el nodo padre y los nodos hijos son las palabras particulares que se encuentren en el texto. Un supuesto importante en Naive Bayes es que la presencia de cada palabra importante es independiente de las otras, lo cual es algo irrealista. No obstante, el modelo se desempeña formidable.\n",
    "\n",
    "Para ello se utiliza el dataset de crítica de películas con 25.000 datos de entrenamiento y otros 25.000 de validación. Se usará la librería _tm_ de R para operaciones de minería de texto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> [` tm{tm}`](https://cran.r-project.org/web/packages/tm/tm.pdf)\n",
    "\n",
    "> [` caret{caret}`](ftp://cran.r-project.org/pub/R/web/packages/caret/caret.pdf)\n",
    "\n",
    "> [` e1071{e1071}`](https://cran.r-project.org/web/packages/e1071/e1071.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: NLP\n",
      "Loading required package: lattice\n",
      "Loading required package: ggplot2\n",
      "\n",
      "Attaching package: ‘ggplot2’\n",
      "\n",
      "The following object is masked from ‘package:NLP’:\n",
      "\n",
      "    annotate\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Instale y cargue las siguientes librerias\n",
    "library(tm)                                     \n",
    "library(caret)\n",
    "library(\"e1071\")                          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Lectura de datos\n",
    "\n",
    "url<-\"http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\"      # Link al data set\n",
    "\n",
    "download.file(url,                                                         # URL del dataset\n",
    "              destfile=\"tmp.tar.gz\")                                       # Archivo de destino\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Los datos descargados quedan en directorio y se descomprimen\n",
    "\n",
    "untar(\"tmp.tar.gz\")                                                        # Descompresión del archivo TAR\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La carpeta que se descomprimió _aclImdb_ tiene unas subcarpetas llamadas _train y test_ cada una con los archivos .txt que contiene cada review de cada pelicula separados por negativos y positivos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in UseMethod(\"meta\", x): no applicable method for 'meta' applied to an object of class \"character\"\n",
     "output_type": "error",
     "traceback": [
      "Error in UseMethod(\"meta\", x): no applicable method for 'meta' applied to an object of class \"character\"\nTraceback:\n",
      "1. meta(nb_all[[1]])"
     ]
    }
   ],
   "source": [
    "## Asignación de variables\n",
    "\n",
    "path_to_neg_folder <- paste0(getwd(),                                      # Pegar directorio local\n",
    "                             \"/aclImdb/train/neg\")                         # Direccion a los negativos\n",
    "path_to_pos_folder <- paste0(getwd(),              \n",
    "                             \"/aclImdb/train/pos\")                         # Direccion a los positivos\n",
    "   \n",
    "nb_pos             <- Corpus(                                              # Devuelve la colección de documentos\n",
    "                            DirSource(path_to_pos_folder),                 # Direccion de los documentos\n",
    "                            readerControl = list(language = \"en\"))         # Lenguaje de los docuemtos\n",
    "nb_neg             <- Corpus(\n",
    "                            DirSource(path_to_neg_folder), \n",
    "                            readerControl = list(language = \"en\"))\n",
    "\n",
    "nb_all  <- c(nb_pos, nb_neg, recursive = T)                                 # Concatenar colecciones \n",
    "\n",
    "meta(nb_all[[1]])                                                           # Datos del primer archivo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe que los archivos se encuentra de la forma _**#pelicula_calificacion**_ donde la calificación es una escala de 0 a 10, siendo 10 la mejor calificación. Ahora se crea un vector con los nombres de los archivos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Crear vector de nombres\n",
    "\n",
    "ids <- sapply( 1 : length(nb_all),                     # Vector de 1 hasta el numero de peliculas\n",
    "              function(x) meta(nb_all[[x]], \"id\"))     # Extaer el ID\n",
    "                  \n",
    "head(ids)                                              # Primeros seis datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Posteriormente se extrae la calificación de cada película con la función _sub_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Obtener las calificaciones de cada pelicula\n",
    "\n",
    "scores <- as.numeric(sapply(ids,                                                     # Nombre de los archivos\n",
    "                            function(x) sub(\"[0-9]+_([0-9]+)\\\\.txt\", \"\\\\1\", x)))     # Expresión regular para encontrar la calificación\n",
    "                                \n",
    "scores <- factor(ifelse(scores >= 5, \"positive\", \"negative\"))                        # Forzar clase de positivo-negativo con limite de calificacion 5\n",
    "                                \n",
    "summary(scores)                                                                      # Resumen de las calificacion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuando se trabaja con minería de texto, usualemente uno asocia palabras a los sentimientos ya que si una critica presenta adjetivos como _aburrido, cliché, horrible_ tiende asociarse con una mala crítica, mientras que palabras como _Excelente, genial, divertida_ son tendientes a una buena crítica. \n",
    "\n",
    "Por lo tanto, antes de empezar se realizan pasos de pre-procesamiento como convertir las palabras a minúsculas, remover puntuaciones, numeros o palabras muertas (the, of, on, over, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Pre-procesamiento de datos\n",
    "\n",
    "nb_all <- tm_map(nb_all, \n",
    "                 content_transformer(removeNumbers))           # Remover los números\n",
    "\n",
    "nb_all <- tm_map(nb_all, \n",
    "                 content_transformer(removePunctuation))       # Remover caracteres de puntuación\n",
    "\n",
    "nb_all <- tm_map(nb_all, \n",
    "                 content_transformer(tolower))                 # Forzar a minúscula\n",
    "\n",
    "nb_all <- tm_map(nb_all, \n",
    "                 content_transformer(removeWords),             # Remover palabras \n",
    "                 stopwords(\"english\"))                         # Palabras muertas\n",
    "\n",
    "nb_all <- tm_map(nb_all, \n",
    "                 content_transformer(stripWhitespace))         # Quitar espacios en blanco"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora se procede a estimar las características a través de una **_matriz de terminos documentales_** donde cada fila corresponde a un documento y las columnas son las palabras de dicho documento. Cada entrada es un 0 o 1 donde indica la falta o la presencia de dicha palabra en el documento, respectivamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Creación de matriz\n",
    "\n",
    "nb_dtm <- DocumentTermMatrix(nb_all)\n",
    "\n",
    "dim(nb_dtm)    # Dimensiones de la matriz\n",
    "\n",
    "nb_dtm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La matriz tiene 118.235 columnas lo que indica que esas son las palabras distintas en todos los documentos. Adicional se observa que la matriz es _**sparse**_, un tipo especial de matriz que contiene una gran cantidad de 0. En este caso existen 2.493.738 de valores distintos de cero y 2.953.381.262 de campos iguales a 0. Una forma de reducir la dimensionalidad de esta matriz es quitar las columnas que tenegan mayor número de ceros, donde se establece un porcentaje de aceptación que en este caso será del 99%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Reducción matriz \n",
    "\n",
    "nb_dtm <- removeSparseTerms(x = nb_dtm, \n",
    "                            sparse = 0.99)  # Porcentaje de aceptación\n",
    "\n",
    "dim(nb_dtm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe que se redujo a 1603 columnas. Luego, se fuerza la matriz a ser binaria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Forzar a matriz de 0 y 1\n",
    "\n",
    "nb_dtm <- weightBin(nb_dtm)\n",
    "\n",
    "inspect(nb_dtm[10:16, 1:6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez la matriz como se necesita, se procede a realizar el modelo Naive Bayes, donde primero se crea los datos de entranmiento y validación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Particionamos sets training y testing\n",
    "set.seed(443452342)                                                    # Semilla aleatoria\n",
    "\n",
    "nb_df              <- as.data.frame(as.matrix(nb_dtm))                 # Convertir a data.frame\n",
    " \n",
    "nb_sampling_vector <- createDataPartition(scores,                      # Crear vector de muestreo\n",
    "                                          p = 0.80,                    # Porcentaje de muestreo\n",
    "                                          list = FALSE)                # Devolver lista es falso\n",
    "\n",
    "nb_df_train        <- nb_df[nb_sampling_vector,]                       # Variables predictoras de entrenamiento\n",
    "nb_df_test         <- nb_df[-nb_sampling_vector,]                      # Variables predictoras de validación\n",
    "\n",
    "scores_train       <- scores[nb_sampling_vector]                       # Variable respuesta de entrenamiento\n",
    "scores_test        <- scores[-nb_sampling_vector]                      # Variable respuesta de validación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creación del modelo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Generar el clasificador Naive Bayes\n",
    "\n",
    "nb_model <- naiveBayes(nb_df_train,         # Variables predictoras de entrenamiento\n",
    "                       scores_train)        # Variable respuesta de entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicción y porcentaje de ajuste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Predicciones y ajuste\n",
    "\n",
    "nb_train_predictions <- predict(nb_model,        # Modelo de Naive Bayes\n",
    "                                nb_df_train)     # Variables predictoras de entrenamiento\n",
    "\n",
    "mean(nb_train_predictions == scores_train)       # Porcenjate de acierto\n",
    "\n",
    "table(actual = scores_train,                     # Valores reales\n",
    "      predictions = nb_train_predictions)        # Valores predecidos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluación del modelo con los datos de validación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Predicciones y evaluación de precisión\n",
    "\n",
    "nb_test_predictions <- predict(nb_model,         # Modelo de Naive Bayes\n",
    "                               nb_df_test)       # Variables predictoras de validación\n",
    "\n",
    "mean(nb_test_predictions == scores_test)         # Porcentaje de acierto\n",
    "\n",
    "table(actual = scores_test,                      # Valores reales\n",
    "      predictions = nb_test_predictions)         # Valores predecidos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Ejercicio.--** Utilice la base de datos de imagenes con letras escritas proporcionada por Kaggle para predecir que tipo de letra es utilizando modelo básico de Naive Bayes.\n",
    "\n",
    "[Datos](https://drive.google.com/file/d/0B4psHlllKLPUX0JYVFpLblNwZDA/view?usp=sharing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelos de Markov Ocultos\n",
    "[Contenido](#Contenido)\n",
    "\n",
    "\n",
    "Los modelos de Markov ocultos (HMM) son redes bayesianas con una estructura repetitiva entre ciertos estados que se puede utilizar para predecir secuencias. El diagrama básico de cómo se ve un HMM es:\n",
    "\n",
    "<img src=\"images/hmm.png\" height=500 width=400>\n",
    "\n",
    "Al observar la secuencia avanza de izquierda a derecha donde cada nodo del camino contiene un par de nodos conectados. Los nodos $C_{i}$ son conocidos como estados latentes, escondidos o solo estados dificiles de observar, donde los nodos $O_{i}$ son los estados observados. Como las redes bayesianas, las observaciones son independientes entre ellas dado su estado correspondiente. En los nodos escondidos, se produce una observación o un símbolo que hacen parte de la sequencia.\n",
    "\n",
    "Estos modelos son ampliamente usados en el procesamiento natural de lenguaje (NLP) en la tarea de obtener una parte del habla y sacar la sequencia de las _\"etiquetas\"_ (Sustantivo, adjetivo, adverbio, etc). También se utilizan en reconocimiento de imagenes, de intrusos en una red, entre otros.\n",
    "\n",
    "Usualmente, se tiene una coleccion de sequencias etiquetadas con su respectivo estado donde, análogamente al clasificador ingenuo Bayesiano, se usa los conteos de frecuencia relativos para estimar la probabilidad inicial del algortimo. Cuando no se tienen clasificados los datos, la tarea es más dificil ya que pueden ser varios estados y se tienen que probar las combinaciones posibles. Un posible método es através del algoritmo Baum-Welch.\n",
    "\n",
    "Una vez se estiman los parámetros del modelo, la cuestión es cómo predecir la sequencia más probable de estados detrás de una secuencia de observaciones. A continuación, se hace una inroducción de este tipo de algoritmos.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aplicación HMM\n",
    "[Contenido](#Contenido)\n",
    "\n",
    "Dentro del campo de la biología los modelos HMM son ampliamente usados para la prediccion de secuencias genéticas. El DNA se compone de cuatro moleculas fundamentales: _Timinia, Citosina, Adenina y Guanina_, donde el orden en que estas aparecen en la secuencia codifica la información genética que contiene el ADN. \n",
    "\n",
    "Un problema interesante es encontrar una secuencia promotora que juegan un papel importante en regular la transcripción de genes. Para esta tarea, se utiliza el HMM que discrimine qué secuencias son promotoras y que otras no."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> [`HMM {HMM}`](https://cran.r-project.org/web/packages/HMM/HMM.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Descargue e instale las siguientes librerias\n",
    "library(\"HMM\")                                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Lectura de datos\n",
    "\n",
    "link      <- paste0(\"https://archive.ics.uci.edu/ml/machine-learning-databases/\",      # Link de los datos\n",
    "             \"molecular-biology/promoter-gene-sequences/promoters.data\")\n",
    "\n",
    "promoters <- read.csv(link,                                                 # Datos\n",
    "                      header = F,                                           # Sin encabezado\n",
    "                      dec = \",\",                                            # Indicador decimal\n",
    "                      strip.white = TRUE,                                   # Elimina espacios en blanco al principio\n",
    "                      stringsAsFactors = FALSE)                             # Cadenas de texto no se forzan a ser factores\n",
    "\n",
    "promoters[1,]                                                               # Primer registro de la secuencia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note que la primera columna denota las cadenas promotoras o no (+ o -), por lo tanto se divide el conjunto de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Separar cadenas promotoras\n",
    "\n",
    "positive_observations <- subset(promoters,   # Data \n",
    "                                V1 == '+',   # Cadenas promotoras (+)\n",
    "                                3)           # Seleccionamos la columna 3\n",
    "\n",
    "negative_observations <- subset(promoters,   # Data\n",
    "                                V1 == '-',   # Cadenas promotoras (+)\n",
    "                                3)           # Seleccionamos la columna 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para el modelo HMM, es necesario concatenar todas las cadenas de la misma clase, pero sin perder el inicio y el fin de cada uno. Para ello se coloca una S al principio de cada cadena y una X al final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Identificar el inicio y final de cada cadena\n",
    "\n",
    "positive_observations <- sapply(positive_observations,                  # Cadenas\n",
    "                                function(x) paste(\"S\", x, \"X\", sep=\"\")) # Pegar S al principio y X al final\n",
    "                                    \n",
    "negative_observations <- sapply(negative_observations,                  # Cadenas\n",
    "                                function(x) paste(\"S\", x, \"X\", sep=\"\")) # Pegar S al principio y X al final\n",
    "    \n",
    "positive_observations[1]                                                # Primer dato"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora se divide la secuencia en cada una de sus moleculas con la función `strsplit()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Separar las cadenas\n",
    "\n",
    "positive_observations <- strsplit(positive_observations, \"\")      # Separar la cadena en cada molecula (letra)\n",
    "negative_observations <- strsplit(negative_observations, \"\")      \n",
    "\n",
    "head(positive_observations[[1]], n = 15)                          # Mostrar 15 primeros datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora que los datos están organizados, hay definir las matrices de probabilidad con los 6 estados que se presentan (4 moleculas más X y S)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Estimación de las matrices de probabilidad\n",
    "\n",
    "states                          <- c(\"S\", \"X\", \"a\", \"c\", \"g\", \"t\")     # Estados de la posición de la cadena\n",
    "symbols                         <- c(\"S\", \"X\", \"a\", \"c\", \"g\", \"t\")    # Simbolos de cada estado\n",
    "\n",
    "startingProbabilities           <- c(1,0,0,0,0,0)       # Probabilidades iniciales\n",
    "emissionProbabilities           <- diag(6)              # Matriz 6x6 con 1's en su diagonal\n",
    "\n",
    "colnames(emissionProbabilities) <- states     # Asignamos nombre a las columnas\n",
    "rownames(emissionProbabilities) <- symbols    # Asignamos nombre a las filas\n",
    "\n",
    "emissionProbabilities                         # Mostrar la matriz "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definir la función `calculateTransitionProbabilities` que calcula la probabilidad de transición de un estado a otro. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Funcion para calcular probabilidades de transición\n",
    "\n",
    "calculateTransitionProbabilities <- function(data, states) {\n",
    "    \n",
    "    # Crear matriz\n",
    "             transitionProbabilities  <- matrix(0,                # Cero en las entradas\n",
    "                                               length(states),    # numero de Filas\n",
    "                                               length(states))    # Numero de columnas\n",
    "    \n",
    "    # Nombre de la filas y columnas \n",
    "    colnames(transitionProbabilities) <- states\n",
    "    rownames(transitionProbabilities) <- states\n",
    "    \n",
    "    for (index in 1:(length(data) - 1)) {\n",
    "        current_state <- data[index]                 # Estado actual\n",
    "        next_state    <- data[index + 1]             # Proximo estado\n",
    "        transitionProbabilities[current_state, next_state] <-transitionProbabilities[current_state, next_state] + 1 # Se hace el conteo de los passos de estado\n",
    "    }\n",
    "    \n",
    "    # Extraer frencuencias relativas\n",
    "    transitionProbabilities <- sweep(transitionProbabilities,              # Barrer por la matriz de ocurrencias\n",
    "                                     1,                                    # Recorrer por filas\n",
    "                                     rowSums(transitionProbabilities),     # Estadística de suma de las filas\n",
    "                                     FUN = \"/\")                            # Dividir entre las filas\n",
    "    \n",
    "    return(transitionProbabilities)                                        # Devolver matriz\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dado que hay tan pocas observaciones, es recomendable usar validación cruzada dejando uno afuera para mejorar la estimación del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Validación cruzada dejando uno afuera y matrices\n",
    "\n",
    "negative_observation        <-Reduce(function(x, y) c(x, y),     # Reducir la matriz\n",
    "    negative_observations,                                       # Datos de entrenamiento\n",
    "    c())\n",
    "    \n",
    "(transitionProbabilitiesNeg <- calculateTransitionProbabilities(negative_observation,  # Valores ajustados \n",
    "                                                                states))               # Valores de los estados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inciamos el HMM con la función initHMM de la librería _HMM_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Inicializar modelos HMM\n",
    "\n",
    "negative_hmm <- initHMM(states,                                        # Estados\n",
    "                        symbols,                                       # Símbolos\n",
    "                        startProbs = startingProbabilities,            # Probabilidades iniciales\n",
    "                        transProbs = transitionProbabilitiesNeg,       # Probabilidades de transición\n",
    "                        emissionProbs = emissionProbabilities)         # Probabilidades de emision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluación de las predicciones correctas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Validación del ajuste\n",
    "incorrect <- 0             # Inicializar vector incorrect\n",
    "\n",
    "# Hacer un loop para contar los incorrectos\n",
    "for (obs in 1 : length(positive_observations)) {\n",
    "    positive_observation <- Reduce(function(x, y) c(x, y), positive_observations[-obs], c())               # Quitar una observación\n",
    "        \n",
    "    transitionProbabilitiesPos <- calculateTransitionProbabilities(positive_observation, states)           # Calcular las matrices de transición\n",
    "        \n",
    "    positive_hmm <- initHMM(states, symbols,startProbs = startingProbabilities,                            # Iniciar el modelo HMM\n",
    "                            transProbs = transitionProbabilitiesPos,emissionProbs = emissionProbabilities)\n",
    "        \n",
    "    test_observation <- positive_observations[[obs]]               # Observaciones de test\n",
    "        \n",
    "    final_index     <- length(test_observation)                    # Longitud de cuántas observaciones\n",
    "        \n",
    "    pos_probs      <- exp(forward(positive_hmm, test_observation)) # Matriz con el logaritmo de la probabilidad.\n",
    "    neg_probs      <- exp(forward(negative_hmm, test_observation)) # en cada paso\n",
    "        \n",
    "    pos_seq_prob   <- sum(pos_probs[, final_index])                # Sumar las cadenas positivas y negativas\n",
    "    neg_seq_prob   <- sum(neg_probs[, final_index])\n",
    "        \n",
    "    if (pos_seq_prob < neg_seq_prob) {incorrect <- incorrect + 1}  # Contar el incorrecto\n",
    "}\n",
    "\n",
    "incorrect                                                          # Mostrar el número de incorrectos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Iniciar el modelo HMM para promotores negativos\n",
    "\n",
    "positive_observation <- Reduce(function(x, y) c(x, y), positive_observations, c())\n",
    "    \n",
    "transitionProbabilitiesPos <- calculateTransitionProbabilities(positive_observation, states)\n",
    "    \n",
    "positive_hmm <- initHMM(states, \n",
    "                       symbols, \n",
    "                       startProbs = startingProbabilities, \n",
    "                       transProbs = transitionProbabilitiesPos,\n",
    "                       emissionProbs = emissionProbabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for (obs in 1:length(negative_observations)) {\n",
    "    negative_observation<-Reduce(function(x, y) c(x, y), negative_observations[-obs], c())\n",
    "        \n",
    "    transitionProbabilitiesNeg <-calculateTransitionProbabilities(negative_observation, states)\n",
    "        \n",
    "    negative_hmm     <- initHMM(states, \n",
    "                                symbols, \n",
    "                                startProbs = startingProbabilities,  \n",
    "                                transProbs = transitionProbabilitiesNeg, \n",
    "                                emissionProbs = emissionProbabilities)\n",
    "        \n",
    "    test_observation <- negative_observations[[obs]]\n",
    "        \n",
    "    final_index      <- length(test_observation)\n",
    "        \n",
    "    pos_probs        <- exp(forward(positive_hmm,test_observation))\n",
    "    neg_probs        <- exp(forward(negative_hmm,test_observation))\n",
    "        \n",
    "    pos_seq_prob     <- sum(pos_probs[, final_index])\n",
    "    neg_seq_prob     <- sum(neg_probs[, final_index])\n",
    "    if (pos_seq_prob > neg_seq_prob) incorrect <- incorrect+1\n",
    "}\n",
    "    \n",
    "incorrect\n",
    "    \n",
    "(cross_validation_accuracy <- 1 - (incorrect/nrow(promoters)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Ejercicio.--**  Una firma inversora en bolsa necesita saber para un grupo de acciones en las cuales tiene invertida una gran cantidad de capital cuales son los momentos al alza (bull) o a la baja (bear) con el fin de planear sus estrategías de compra-venta así como identificar oportunidades de invertir.\n",
    "\n",
    "Se debe realizar un modelo donde a partir de la entrada de una serie de tiempo financiera prediga si la acción va a subir o bajar en una determinada ventana de tiempo. Luego de un análisis de la literatura, encuentra que los modelos de HMM pueden predecir si una serie de tiempo subirá o caerá en un régimen de tiempo.\n",
    "\n",
    "Para descargar las series de tiempo, utilice la librería [Quandl](https://www.quandl.com/tools/r). Adicionalmente, realice todos los supuestos que requiera, así como ventana de tiempo de la inversión o la acción con la cual va a trabajar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "[Contenido](#Contenido)\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.3.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
